# â„ï¸ U-Net Replicating

This repository contains a PyTorch replication of the **U-Net: Convolutional Networks for Biomedical Image Segmentation** model. The goal is to reproduce the **U-Net architecture** for accurate pixel-wise biomedical image segmentation.

> âš ï¸ Note: Elastic deformation is **not included** in the augmentation. Only rotation and shift are implemented.

- Only the **original U-Net configuration** is fully implemented.  
- The network consists of a **contracting path (encoder)**, a **bottleneck**, and an **expansive path (decoder)** with skip connections (mirroring) to preserve spatial details.  
- The implementation uses 3Ã—3 convolutions, ReLU activations, max pooling, and 2Ã—2 up-convolutions.  

**Paper:** [U-Net: Convolutional Networks for Biomedical Image Segmentation (MICCAI 2015)](https://arxiv.org/abs/1505.04597)

---


## ğŸ–¼ Overview â€“ U-Net Architecture

![U-Net Overview](images/figmix.jpg)  
*Figure:* Uâ€‘Net architecture showing **contracting path (encoder)**, **bottleneck**, **expansive path (decoder)**, and skip connections for precise pixel-wise segmentation.

- **Contracting Path (Encoder):** Reduces spatial size while increasing feature channels. Each block: 3Ã—3 Conv â†’ ReLU â†’ 3Ã—3 Conv â†’ ReLU â†’ MaxPool.  
- **Bottleneck:** Compresses deepest feature maps (smallest spatial size, highest channels) before expansion.  
- **Expansive Path (Decoder):** Upsamples features, concatenates with corresponding encoder outputs (skip connections), applies conv blocks.  
- **Final Layer:** 1Ã—1 Conv maps features to the number of segmentation classes.  
- **Key Idea:** Skip connections preserve spatial details, allowing precise segmentation even in deep networks.

---

### ğŸ”‘ Key Formulas

1. **Convolutional Layer (ConvBlock):**  

$$y = f(W * x + b)$$

- Standard 3Ã—3 convolution, ReLU activation.

2. **Up-Convolution (Decoder):**  

$$y_\text{up} = \text{Conv2d}(\text{Upsample}(x_\text{prev}) \oplus x_\text{skip})$$

- Upsample previous feature map, concatenate with encoder feature map, apply conv block.

3. **Final Pixel-wise Prediction:**  

$$\hat{y}_{i,j,c} = \text{softmax}(y_{i,j,c})$$

- For each pixel $(i,j)$, outputs class probabilities $c$.

---

## ğŸ— Project Structure

```bash
U-Net-Replicating/
â”‚
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ unet.py
â”‚   â”œâ”€â”€ conv_block.py
â”‚   â”œâ”€â”€ upconv_block.py
â”‚   â””â”€â”€ init_weights.py
â”‚
â”œâ”€â”€ training_utils/
â”‚   â”œâ”€â”€ augmentation.py
â”‚   â”œâ”€â”€ loss.py
â”‚   â””â”€â”€ optimizer.py
â”‚
â”œâ”€â”€ configs/
â”‚   â””â”€â”€ config.py
â”‚
â”œâ”€â”€ scripts/
â”‚   â””â”€â”€ preprocess_dataset.py
â”‚
â”œâ”€â”€ images/
â”‚   â””â”€â”€ figmix.jpg
â”‚
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md

```

---

## ğŸ”— Feedback

For questions or feedback, contact: [barkin.adiguzel@gmail.com](mailto:barkin.adiguzel@gmail.com)





